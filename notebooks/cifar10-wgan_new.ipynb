{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Training Vanilla GAN on CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch-summary in c:\\users\\warre\\anaconda3\\envs\\pytorch\\lib\\site-packages (1.4.5)\n"
     ]
    }
   ],
   "source": [
    "# import necessary dependencies\n",
    "import argparse\n",
    "import os, sys\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "!pip install torch-summary\n",
    "from torchsummary import summary\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import gitpath\n",
    "HOME_PATH = gitpath.root()\n",
    "sys.path.append(HOME_PATH)\n",
    "\n",
    "from models.WGAN_new import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperParams:\n",
    "    def __init__(self):\n",
    "        # Constance hyperparameters. They have been tested and don't need to be tuned.\n",
    "        self.n_epochs = 50\n",
    "        self.batch_size = 64\n",
    "        self.lr = 0.0002\n",
    "        self.n_critic = 5\n",
    "        self.clip_value = 0.01\n",
    "        self.n_workers = 8\n",
    "        self.latent_dim = 100\n",
    "        self.img_size = 32\n",
    "        self.channels = 3\n",
    "        self.sample_interval = 500\n",
    "        self.imgsave_path = os.path.join(HOME_PATH, 'images', 'wgan_new')\n",
    "        self.CHECKPOINT_FOLDER = os.path.join(HOME_PATH, 'saved_model', 'wgan_new')\n",
    "        \n",
    "params = HyperParams()\n",
    "os.makedirs(params.imgsave_path, exist_ok=True)\n",
    "os.makedirs(params.CHECKPOINT_FOLDER, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Step 1: Set up preprocessing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# useful libraries\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010))\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# do NOT change these\n",
    "import torchvision.datasets as dset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# a few arguments, do NOT change these\n",
    "DATA_ROOT = os.path.join(HOME_PATH, \"data\")\n",
    "\n",
    "# construct dataset\n",
    "dataset = dset.CIFAR10(\n",
    "    root=DATA_ROOT,\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform \n",
    ")\n",
    "\n",
    "# construct dataloader\n",
    "dataloader = DataLoader(\n",
    "    dataset, \n",
    "    batch_size=params.batch_size,  # your code\n",
    "    shuffle=True,     # your code\n",
    "    num_workers=params.n_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Step 3: Instantiate your SimpleNN model and deploy it to GPU devices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run on GPU...\n"
     ]
    }
   ],
   "source": [
    "# specify the device for computation\n",
    "\n",
    "# GPU check                \n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "if device =='cuda':\n",
    "    print(\"Run on GPU...\")\n",
    "else:\n",
    "    print(\"Run on CPU...\")\n",
    "\n",
    "# Model Definition  \n",
    "generator = Generator(params.latent_dim).to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "# Check if on GPU\n",
    "assert(next(generator.parameters()).is_cuda)\n",
    "assert(next(discriminator.parameters()).is_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Step 4: Set up the loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# hyperparameters according to ResNet paper section 4.2\n",
    "\n",
    "# Add optimizer\n",
    "optimizerG = optim.RMSprop(generator.parameters(), lr=params.lr)\n",
    "optimizerD = optim.RMSprop(discriminator.parameters(), lr=params.lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Step 5: Start the training process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Training starts!\n",
      "==================================================\n",
      "Epoch 0:\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Mismatch in shape: grad_output[0] has a shape of torch.Size([1]) and output[0] has a shape of torch.Size([64, 1]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Warre\\OneDrive\\桌面\\Duke\\ECE 661\\ECE661-Fall2022-GANs\\notebooks\\cifar10-wgan_new.ipynb 单元格 12\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Warre/OneDrive/%E6%A1%8C%E9%9D%A2/Duke/ECE%20661/ECE661-Fall2022-GANs/notebooks/cifar10-wgan_new.ipynb#X14sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m \u001b[39m# backpropagation\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Warre/OneDrive/%E6%A1%8C%E9%9D%A2/Duke/ECE%20661/ECE661-Fall2022-GANs/notebooks/cifar10-wgan_new.ipynb#X14sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m optimizerD\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Warre/OneDrive/%E6%A1%8C%E9%9D%A2/Duke/ECE%20661/ECE661-Fall2022-GANs/notebooks/cifar10-wgan_new.ipynb#X14sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m loss_D\u001b[39m.\u001b[39;49mbackward(torch\u001b[39m.\u001b[39;49mcuda\u001b[39m.\u001b[39;49mFloatTensor([\u001b[39m1\u001b[39;49m]))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Warre/OneDrive/%E6%A1%8C%E9%9D%A2/Duke/ECE%20661/ECE661-Fall2022-GANs/notebooks/cifar10-wgan_new.ipynb#X14sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m optimizerD\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Warre/OneDrive/%E6%A1%8C%E9%9D%A2/Duke/ECE%20661/ECE661-Fall2022-GANs/notebooks/cifar10-wgan_new.ipynb#X14sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m \u001b[39m# calculate percentage of confidence\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Warre\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[1;32mc:\\Users\\Warre\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\autograd\\__init__.py:166\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    162\u001b[0m inputs \u001b[39m=\u001b[39m (inputs,) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(inputs, torch\u001b[39m.\u001b[39mTensor) \u001b[39melse\u001b[39;00m \\\n\u001b[0;32m    163\u001b[0m     \u001b[39mtuple\u001b[39m(inputs) \u001b[39mif\u001b[39;00m inputs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mtuple\u001b[39m()\n\u001b[0;32m    165\u001b[0m grad_tensors_ \u001b[39m=\u001b[39m _tensor_or_tensors_to_tuple(grad_tensors, \u001b[39mlen\u001b[39m(tensors))\n\u001b[1;32m--> 166\u001b[0m grad_tensors_ \u001b[39m=\u001b[39m _make_grads(tensors, grad_tensors_, is_grads_batched\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    167\u001b[0m \u001b[39mif\u001b[39;00m retain_graph \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n",
      "File \u001b[1;32mc:\\Users\\Warre\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\autograd\\__init__.py:50\u001b[0m, in \u001b[0;36m_make_grads\u001b[1;34m(outputs, grads, is_grads_batched)\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mIf `is_grads_batched=True`, we interpret the first \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     39\u001b[0m                            \u001b[39m\"\u001b[39m\u001b[39mdimension of each grad_output as the batch dimension. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     40\u001b[0m                            \u001b[39m\"\u001b[39m\u001b[39mThe sizes of the remaining dimensions are expected to match \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     47\u001b[0m                            \u001b[39m\"\u001b[39m\u001b[39mIf you only want some tensors in `grad_output` to be considered \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     48\u001b[0m                            \u001b[39m\"\u001b[39m\u001b[39mbatched, consider using vmap.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     49\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 50\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mMismatch in shape: grad_output[\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     51\u001b[0m                            \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(grads\u001b[39m.\u001b[39mindex(grad)) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m] has a shape of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     52\u001b[0m                            \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(grad\u001b[39m.\u001b[39mshape) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m and output[\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     53\u001b[0m                            \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(outputs\u001b[39m.\u001b[39mindex(out)) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m] has a shape of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     54\u001b[0m                            \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(out\u001b[39m.\u001b[39mshape) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     55\u001b[0m \u001b[39mif\u001b[39;00m out\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mis_complex \u001b[39m!=\u001b[39m grad\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mis_complex:\n\u001b[0;32m     56\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mFor complex Tensors, both grad_output and output\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     57\u001b[0m                        \u001b[39m\"\u001b[39m\u001b[39m are required to have the same dtype.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     58\u001b[0m                        \u001b[39m\"\u001b[39m\u001b[39m Mismatch in dtype: grad_output[\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     61\u001b[0m                        \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(outputs\u001b[39m.\u001b[39mindex(out)) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m] has a dtype of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     62\u001b[0m                        \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(out\u001b[39m.\u001b[39mdtype) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Mismatch in shape: grad_output[0] has a shape of torch.Size([1]) and output[0] has a shape of torch.Size([64, 1])."
     ]
    }
   ],
   "source": [
    "# some hyperparameters\n",
    "# total number of training epochs\n",
    "start_epoch = 0\n",
    "\n",
    "# start the training/validation process\n",
    "best_loss_g = 1e20\n",
    "best_loss_d = 1e20\n",
    "\n",
    "start = time.time()\n",
    "print(\"==> Training starts!\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# store loss learning curve\n",
    "g_loss_lst = []\n",
    "d_loss_lst = []\n",
    "\n",
    "fixed_random_z = torch.randn(params.batch_size, params.latent_dim).to(device)\n",
    "\n",
    "for i in range(start_epoch, params.n_epochs):\n",
    "    epoch_start = time.time()\n",
    "    print(\"Epoch %d:\" %i)\n",
    "    # this help you compute the training accuracy\n",
    "    total_examples = 0\n",
    "    correct_examples = 0\n",
    "\n",
    "    g_loss = []\n",
    "    d_loss = []\n",
    "    \n",
    "    # Train the model for 1 epoch.\n",
    "    for batch_idx, (inputs, targets) in enumerate(dataloader):\n",
    "        \n",
    "        inputs = inputs.float().to(device)\n",
    "        batch_size = inputs.size(0)\n",
    "        \n",
    "        # generate fake images\n",
    "        z = torch.randn(batch_size, params.latent_dim).to(device)\n",
    "        gen_imgs = generator(z)\n",
    "        \n",
    "        ####################################\n",
    "        # Train Discriminator\n",
    "        ###################################\n",
    "        # Ref: WGAN paper page 8 Algo 1\n",
    "    \n",
    "        # clipping to satisfy Lipschitz constraint\n",
    "        for p in discriminator.parameters():\n",
    "            p.data.clamp_(-params.clip_value, params.clip_value)\n",
    "\n",
    "        loss_real = torch.mean(discriminator(inputs))\n",
    "        loss_fake = -torch.mean(discriminator(gen_imgs.detach()))\n",
    "        loss_D = loss_fake + loss_real\n",
    "\n",
    "        # backpropagation\n",
    "        optimizerD.zero_grad()\n",
    "        loss_D.backward()\n",
    "        optimizerD.step()\n",
    "\n",
    "        # calculate percentage of confidence\n",
    "        d_loss.append(loss_D.cpu().detach().numpy())\n",
    "\n",
    "        ####################################\n",
    "        \n",
    "        if batch_idx % params.n_critic == 0:\n",
    "            ####################################\n",
    "            # Train Generator\n",
    "            ###################################\n",
    "            # maximize generator's ability to fool discriminator\n",
    "\n",
    "            # compute loss\n",
    "            loss_G = torch.mean(discriminator(gen_imgs))\n",
    "            \n",
    "            # backpropagation\n",
    "            optimizerG.zero_grad()\n",
    "            loss_G.backward()\n",
    "            optimizerG.step()\n",
    "\n",
    "            # calculate percentage of confidence\n",
    "            g_loss.append(loss_G.cpu().detach().numpy())\n",
    "            ####################################\n",
    "        \n",
    "        if (batch_idx % params.sample_interval == 0): \n",
    "            batches_done = i * len(dataloader) + batch_idx\n",
    "            save_image(generator(fixed_random_z).data[:40], os.path.join(params.imgsave_path, \"%d.png\" % batches_done), nrow=5, normalize=True)   \n",
    "\n",
    "    avg_loss_g = np.sum(np.asarray(g_loss)) / len(g_loss)\n",
    "    avg_loss_d = np.sum(np.asarray(d_loss)) / len(d_loss)\n",
    "    print(\"Generator loss: %.4f, Discriminator loss: %.4f\"%(avg_loss_g, avg_loss_d))\n",
    "    \n",
    "    g_loss_lst.extend(g_loss)\n",
    "    d_loss_lst.extend(d_loss)\n",
    "    \n",
    "    # save the model checkpoint\n",
    "    state_G = generator.state_dict()\n",
    "    torch.save(state_G, os.path.join(params.CHECKPOINT_FOLDER, 'generator.pth'))\n",
    "    state_D = discriminator.state_dict()\n",
    "    torch.save(state_D, os.path.join(params.CHECKPOINT_FOLDER, 'discriminator.pth'))\n",
    "    print(f\"Epoch finished in {time.time() - epoch_start:.2f}s\")\n",
    "    print(\"\")\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(f\"==> Optimization finished in {time.time() - start:.2f}s!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m运行 \"Python 3.9.10 64-bit\" 的单元格需要 ipykernel 包。\n",
      "\u001b[1;31m运行以下命令，将 \"ipykernel\" 安装到 Python 环境中。\n",
      "\u001b[1;31m命令: \"c:/Users/Warre/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall\""
     ]
    }
   ],
   "source": [
    "plt.plot(g_loss_lst, label='Generator Error')\n",
    "plt.plot(d_loss_lst, label='Discriminator Error')\n",
    "plt.title(\"GAN Learning Curve\")\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:26:10) \n[GCC 11.2.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "d7f2a7996328504c9da638a538617e092c5f6c113e142544f6d693b60dd4d365"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
